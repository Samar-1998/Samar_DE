{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\ndept = [(\"Finance\",10), \n        (\"Marketing\",20), \n        (\"Sales\",30), \n        (\"IT\",40) \n      ]\nrdd = spark.sparkContext.parallelize(dept)\n\ndf = rdd.toDF()\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"83e4af49-3d88-494b-abf2-02161159e07a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- _1: string (nullable = true)\n |-- _2: long (nullable = true)\n\n+---------+---+\n|_1       |_2 |\n+---------+---+\n|Finance  |10 |\n|Marketing|20 |\n|Sales    |30 |\n|IT       |40 |\n+---------+---+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["deptColumns = [\"dept_name\",\"dept_id\"]\ndf2 = rdd.toDF(deptColumns)\ndf2.printSchema()\ndf2.show(truncate=False)\n\ndeptDF = spark.createDataFrame(data=dept, schema = deptColumns)\ndeptDF.printSchema()\ndeptDF.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"795795fa-2a0e-4911-ac98-96ca30e0550a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- dept_name: string (nullable = true)\n |-- dept_id: long (nullable = true)\n\n+---------+-------+\n|dept_name|dept_id|\n+---------+-------+\n|Finance  |10     |\n|Marketing|20     |\n|Sales    |30     |\n|IT       |40     |\n+---------+-------+\n\nroot\n |-- dept_name: string (nullable = true)\n |-- dept_id: long (nullable = true)\n\n+---------+-------+\n|dept_name|dept_id|\n+---------+-------+\n|Finance  |10     |\n|Marketing|20     |\n|Sales    |30     |\n|IT       |40     |\n+---------+-------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StructType,StructField, StringType\ndeptSchema = StructType([       \n    StructField('dept_name', StringType(), True),\n    StructField('dept_id', StringType(), True)\n])\n\ndeptDF1 = spark.createDataFrame(data=dept, schema = deptSchema)\ndeptDF1.printSchema()\ndeptDF1.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e5f8ef3e-9dbf-43e9-845d-7de29cc73c6b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- dept_name: string (nullable = true)\n |-- dept_id: string (nullable = true)\n\n+---------+-------+\n|dept_name|dept_id|\n+---------+-------+\n|Finance  |10     |\n|Marketing|20     |\n|Sales    |30     |\n|IT       |40     |\n+---------+-------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\ndept = [(\"Finance\",10), \n        (\"Marketing\",20), \n        (\"Sales\",30), \n        (\"IT\",40) \n      ]\nrdd = spark.sparkContext.parallelize(dept)\n\ndf = rdd.toDF()\ndf.printSchema()\ndf.show(truncate=False)\n\ndeptColumns = [\"dept_name\",\"dept_id\"]\ndf2 = rdd.toDF(deptColumns)\ndf2.printSchema()\ndf2.show(truncate=False)\n\ndeptDF = spark.createDataFrame(data=dept, schema = deptColumns)\ndeptDF.printSchema()\ndeptDF.show(truncate=False)\n\n\nfrom pyspark.sql.types import StructType,StructField, StringType\ndeptSchema = StructType([       \n    StructField('dept_name', StringType(), True),\n    StructField('dept_id', StringType(), True)\n])\n\ndeptDF1 = spark.createDataFrame(data=dept, schema = deptSchema)\ndeptDF1.printSchema()\ndeptDF1.show(truncate=False)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7e2b8101-41b0-4d1d-ba07-9d75d072b58a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-rdd-to-dataframe","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
