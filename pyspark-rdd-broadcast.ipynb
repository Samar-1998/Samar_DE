{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\nstates = {\"NY\":\"New York\", \"CA\":\"California\", \"FL\":\"Florida\"}\nbroadcastStates = spark.sparkContext.broadcast(states)\n\ndata = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n  ]\n\nrdd = spark.sparkContext.parallelize(data)\n\ndef state_convert(code):\n    return broadcastStates.value[code]\n\nresult = rdd.map(lambda x: (x[0],x[1],x[2],state_convert(x[3]))).collect()\nprint(result)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"78db7f0b-acf4-43b4-af1f-2a828715deca","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["[('James', 'Smith', 'USA', 'California'), ('Michael', 'Rose', 'USA', 'New York'), ('Robert', 'Williams', 'USA', 'California'), ('Maria', 'Jones', 'USA', 'Florida')]\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0c3035e9-26d9-40fa-9e46-004fe244261e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-rdd-broadcast","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
