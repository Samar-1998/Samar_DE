{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\nspark = SparkSession.builder \\\n                    .appName('SparkByExamples.com') \\\n                    .getOrCreate()\n\ndata = [('James','Smith','M',3000),\n  ('Anna','Rose','F',4100),\n  ('Robert','Williams','M',6200), \n]\n\ncolumns = [\"firstname\",\"lastname\",\"gender\",\"salary\"]\ndf = spark.createDataFrame(data=data, schema = columns)\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"df8a6f2b-7927-4e55-bf01-f27581a639eb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+--------+------+------+\n|firstname|lastname|gender|salary|\n+---------+--------+------+------+\n|    James|   Smith|     M|  3000|\n|     Anna|    Rose|     F|  4100|\n|   Robert|Williams|     M|  6200|\n+---------+--------+------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["if 'salary1' not in df.columns:\n    print(\"aa\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ec51db2f-5a9e-467a-85a2-ba7be702b2ba","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["aa\n"]}],"execution_count":0},{"cell_type":"code","source":["# Add new constanct column\nfrom pyspark.sql.functions import lit\ndf.withColumn(\"bonus_percent\", lit(0.3)) \\\n  .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"8db88b37-6554-4c75-a511-c32c2b86d682","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+--------+------+------+-------------+\n|firstname|lastname|gender|salary|bonus_percent|\n+---------+--------+------+------+-------------+\n|    James|   Smith|     M|  3000|          0.3|\n|     Anna|    Rose|     F|  4100|          0.3|\n|   Robert|Williams|     M|  6200|          0.3|\n+---------+--------+------+------+-------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Add column from existing column\ndf.withColumn(\"bonus_amount\", df.salary*0.3) \\\n  .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"33233cfd-56c7-4f4f-98e0-a7c7d4afa431","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+--------+------+------+------------+\n|firstname|lastname|gender|salary|bonus_amount|\n+---------+--------+------+------+------------+\n|    James|   Smith|     M|  3000|       900.0|\n|     Anna|    Rose|     F|  4100|      1230.0|\n|   Robert|Williams|     M|  6200|      1860.0|\n+---------+--------+------+------+------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Add column by concatinating existing columns\nfrom pyspark.sql.functions import concat_ws\ndf.withColumn(\"name\", concat_ws(\",\",df.firstname,df.lastname)) \\\n  .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"dc497795-d009-4d7e-997c-27681fe25daa","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+--------+------+------+---------------+\n|firstname|lastname|gender|salary|           name|\n+---------+--------+------+------+---------------+\n|    James|   Smith|     M|  3000|    James,Smith|\n|     Anna|    Rose|     F|  4100|      Anna,Rose|\n|   Robert|Williams|     M|  6200|Robert,Williams|\n+---------+--------+------+------+---------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import when\ndf.withColumn(\"grade\", \\\n   when((df.salary < 4000), lit(\"A\")) \\\n     .when((df.salary >= 4000) & (df.salary <= 5000), lit(\"B\")) \\\n     .otherwise(lit(\"C\")) \\\n  ).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"dd8c2b0c-f08d-45c1-8d7b-21b9efde6868","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+--------+------+------+-----+\n|firstname|lastname|gender|salary|grade|\n+---------+--------+------+------+-----+\n|    James|   Smith|     M|  3000|    A|\n|     Anna|    Rose|     F|  4100|    B|\n|   Robert|Williams|     M|  6200|    C|\n+---------+--------+------+------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.select(\"firstname\",\"salary\", lit(0.3).alias(\"bonus\")).show()\ndf.select(\"firstname\",\"salary\", lit(df.salary * 0.3).alias(\"bonus_amount\")).show()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e4c8c395-6d51-4f4a-a218-653f26772761","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+------+-----+\n|firstname|salary|bonus|\n+---------+------+-----+\n|    James|  3000|  0.3|\n|     Anna|  4100|  0.3|\n|   Robert|  6200|  0.3|\n+---------+------+-----+\n\n+---------+------+------------+\n|firstname|salary|bonus_amount|\n+---------+------+------------+\n|    James|  3000|       900.0|\n|     Anna|  4100|      1230.0|\n|   Robert|  6200|      1860.0|\n+---------+------+------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["A = df.createOrReplaceTempView(\"PER\")toDF"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"3c351267-6ebe-490d-83b1-b6f0eee92d4d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;36m  File \u001B[0;32m<command-1659152491678930>:1\u001B[0;36m\u001B[0m\n\u001B[0;31m    A = df.createOrReplaceTempView(\"PER\")toDF\u001B[0m\n\u001B[0m                                         ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n","errorSummary":"<span class='ansi-red-fg'>SyntaxError</span>: invalid syntax (<command-1659152491678930>, line 1)","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;36m  File \u001B[0;32m<command-1659152491678930>:1\u001B[0;36m\u001B[0m\n","\u001B[0;31m    A = df.createOrReplaceTempView(\"PER\")toDF\u001B[0m\n","\u001B[0m                                         ^\u001B[0m\n","\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.createOrReplaceTempView(\"PER\")\nspark.sql(\"select firstname,salary, '0.3' as bonus from PER\").show()\nspark.sql(\"select firstname,salary, salary * 0.3 as bonus_amount from PER\").show()\nspark.sql(\"select firstname,salary, current_date() as today_date from PER\").show()\nspark.sql(\"select firstname,salary, \" +\n          \"case salary when salary < 4000 then 'A' \"+\n          \"else 'B' END as grade from PER\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b7ca4706-11ef-4d2e-8edd-a952998c6698","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+------+-----+\n|firstname|salary|bonus|\n+---------+------+-----+\n|    James|  3000|  0.3|\n|     Anna|  4100|  0.3|\n|   Robert|  6200|  0.3|\n+---------+------+-----+\n\n+---------+------+------------+\n|firstname|salary|bonus_amount|\n+---------+------+------------+\n|    James|  3000|       900.0|\n|     Anna|  4100|      1230.0|\n|   Robert|  6200|      1860.0|\n+---------+------+------------+\n\n+---------+------+----------+\n|firstname|salary|today_date|\n+---------+------+----------+\n|    James|  3000|2023-06-13|\n|     Anna|  4100|2023-06-13|\n|   Robert|  6200|2023-06-13|\n+---------+------+----------+\n\n+---------+------+-----+\n|firstname|salary|grade|\n+---------+------+-----+\n|    James|  3000|    B|\n|     Anna|  4100|    B|\n|   Robert|  6200|    B|\n+---------+------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\nspark = SparkSession.builder \\\n                    .appName('SparkByExamples.com') \\\n                    .getOrCreate()\n\ndata = [('James','Smith','M',3000),\n  ('Anna','Rose','F',4100),\n  ('Robert','Williams','M',6200), \n]\n\ncolumns = [\"firstname\",\"lastname\",\"gender\",\"salary\"]\ndf = spark.createDataFrame(data=data, schema = columns)\ndf.show()\n\n\nif 'salary1' not in df.columns:\n    print(\"aa\")\n    \n# Add new constanct column\nfrom pyspark.sql.functions import lit\ndf.withColumn(\"bonus_percent\", lit(0.3)) \\\n  .show()\n  \n#Add column from existing column\ndf.withColumn(\"bonus_amount\", df.salary*0.3) \\\n  .show()\n\n#Add column by concatinating existing columns\nfrom pyspark.sql.functions import concat_ws\ndf.withColumn(\"name\", concat_ws(\",\",\"firstname\",'lastname')) \\\n  .show()\n\n#Add current date\nfrom pyspark.sql.functions import current_date\ndf.withColumn(\"current_date\", current_date()) \\\n  .show()\n\n\nfrom pyspark.sql.functions import when\ndf.withColumn(\"grade\", \\\n   when((df.salary < 4000), lit(\"A\")) \\\n     .when((df.salary >= 4000) & (df.salary <= 5000), lit(\"B\")) \\\n     .otherwise(lit(\"C\")) \\\n  ).show()\n    \n# Add column using select\ndf.select(\"firstname\",\"salary\", lit(0.3).alias(\"bonus\")).show()\ndf.select(\"firstname\",\"salary\", lit(df.salary * 0.3).alias(\"bonus_amount\")).show()\ndf.select(\"firstname\",\"salary\", current_date().alias(\"today_date\")).show()\n\n#Add columns using SQL\ndf.createOrReplaceTempView(\"PER\")\nspark.sql(\"select firstname,salary, '0.3' as bonus from PER\").show()\nspark.sql(\"select firstname,salary, salary * 0.3 as bonus_amount from PER\").show()\nspark.sql(\"select firstname,salary, current_date() as today_date from PER\").show()\nspark.sql(\"select firstname,salary, \" +\n          \"case salary when salary < 4000 then 'A' \"+\n          \"else 'B' END as grade from PER\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"553bd638-c0fd-4672-ab38-f7b5c7a9007a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Add New Column","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
