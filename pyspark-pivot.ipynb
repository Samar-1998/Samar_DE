{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import expr\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\ndata = [(\"Banana\",1000,\"USA\"), (\"Carrots\",1500,\"USA\"), (\"Beans\",1600,\"USA\"), \\\n      (\"Orange\",2000,\"USA\"),(\"Orange\",2000,\"USA\"),(\"Banana\",400,\"China\"), \\\n      (\"Carrots\",1200,\"China\"),(\"Beans\",1500,\"China\"),(\"Orange\",4000,\"China\"), \\\n      (\"Banana\",2000,\"Canada\"),(\"Carrots\",2000,\"Canada\"),(\"Beans\",2000,\"Mexico\")]\n\ncolumns= [\"Product\",\"Amount\",\"Country\"]\ndf = spark.createDataFrame(data = data, schema = columns)\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a801b2cb-be9f-4e16-aeee-d1ae0262e3a0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- Product: string (nullable = true)\n |-- Amount: long (nullable = true)\n |-- Country: string (nullable = true)\n\n+-------+------+-------+\n|Product|Amount|Country|\n+-------+------+-------+\n|Banana |1000  |USA    |\n|Carrots|1500  |USA    |\n|Beans  |1600  |USA    |\n|Orange |2000  |USA    |\n|Orange |2000  |USA    |\n|Banana |400   |China  |\n|Carrots|1200  |China  |\n|Beans  |1500  |China  |\n|Orange |4000  |China  |\n|Banana |2000  |Canada |\n|Carrots|2000  |Canada |\n|Beans  |2000  |Mexico |\n+-------+------+-------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["pivotDF = df.groupBy(\"Product\").pivot(\"Country\").sum(\"Amount\")\npivotDF.printSchema()\npivotDF.show(truncate=False)\n\npivotDF = df.groupBy(\"Product\",\"Country\") \\\n      .sum(\"Amount\") \\\n      .groupBy(\"Product\") \\\n      .pivot(\"Country\") \\\n      .sum(\"sum(Amount)\")\npivotDF.printSchema()\npivotDF.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"df732623-d350-4d91-82a1-42890b1e0d1b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- Product: string (nullable = true)\n |-- Canada: long (nullable = true)\n |-- China: long (nullable = true)\n |-- Mexico: long (nullable = true)\n |-- USA: long (nullable = true)\n\n+-------+------+-----+------+----+\n|Product|Canada|China|Mexico|USA |\n+-------+------+-----+------+----+\n|Orange |null  |4000 |null  |4000|\n|Beans  |null  |1500 |2000  |1600|\n|Banana |2000  |400  |null  |1000|\n|Carrots|2000  |1200 |null  |1500|\n+-------+------+-----+------+----+\n\nroot\n |-- Product: string (nullable = true)\n |-- Canada: long (nullable = true)\n |-- China: long (nullable = true)\n |-- Mexico: long (nullable = true)\n |-- USA: long (nullable = true)\n\n+-------+------+-----+------+----+\n|Product|Canada|China|Mexico|USA |\n+-------+------+-----+------+----+\n|Orange |null  |4000 |null  |4000|\n|Beans  |null  |1500 |2000  |1600|\n|Banana |2000  |400  |null  |1000|\n|Carrots|2000  |1200 |null  |1500|\n+-------+------+-----+------+----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import expr\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\ndata = [(\"Banana\",1000,\"USA\"), (\"Carrots\",1500,\"USA\"), (\"Beans\",1600,\"USA\"), \\\n      (\"Orange\",2000,\"USA\"),(\"Orange\",2000,\"USA\"),(\"Banana\",400,\"China\"), \\\n      (\"Carrots\",1200,\"China\"),(\"Beans\",1500,\"China\"),(\"Orange\",4000,\"China\"), \\\n      (\"Banana\",2000,\"Canada\"),(\"Carrots\",2000,\"Canada\"),(\"Beans\",2000,\"Mexico\")]\n\ncolumns= [\"Product\",\"Amount\",\"Country\"]\ndf = spark.createDataFrame(data = data, schema = columns)\ndf.printSchema()\ndf.show(truncate=False)\n\npivotDF = df.groupBy(\"Product\").pivot(\"Country\").sum(\"Amount\")\npivotDF.printSchema()\npivotDF.show(truncate=False)\n\npivotDF = df.groupBy(\"Product\",\"Country\") \\\n      .sum(\"Amount\") \\\n      .groupBy(\"Product\") \\\n      .pivot(\"Country\") \\\n      .sum(\"sum(Amount)\")\npivotDF.printSchema()\npivotDF.show(truncate=False)\n\n\n\"\"\" unpivot \"\"\"\n\"\"\" unpivot \"\"\"\nunpivotExpr = \"stack(3, 'Canada', Canada, 'China', China, 'Mexico', Mexico) as (Country,Total)\"\nunPivotDF = pivotDF.select(\"Product\", expr(unpivotExpr)) \\\n    .where(\"Total is not null\")\nunPivotDF.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fff1723e-85da-4dd8-b133-cf8fb79f4965","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-pivot","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
