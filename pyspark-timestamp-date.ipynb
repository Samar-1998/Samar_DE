{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\n# Create SparkSession\nspark = SparkSession.builder \\\n          .appName('SparkByExamples.com') \\\n          .getOrCreate()\n\ndf=spark.createDataFrame(\n        data = [ (\"1\",\"2019-06-24 12:01:19.000\")],\n        schema=[\"id\",\"input_timestamp\"])\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c6f1be1b-58f7-4edc-a9cd-80ffd6bc8c7e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- id: string (nullable = true)\n |-- input_timestamp: string (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# Using Cast to convert Timestamp String to DateType\ndf.withColumn('date_type', col('input_timestamp').cast('date')) \\\n       .show(truncate=False)\n\n# Using Cast to convert TimestampType to DateType\ndf.withColumn('date_type', to_timestamp('input_timestamp').cast('date')) \\\n  .show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d66c0d8f-1989-418c-a6f9-37539fc23c2b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-3138232597037740>:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Using Cast to convert Timestamp String to DateType\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m df\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate_type\u001B[39m\u001B[38;5;124m'\u001B[39m, col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_timestamp\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mcast(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m)) \\\n\u001B[1;32m      3\u001B[0m        \u001B[38;5;241m.\u001B[39mshow(truncate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Using Cast to convert TimestampType to DateType\u001B[39;00m\n\u001B[1;32m      6\u001B[0m df\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate_type\u001B[39m\u001B[38;5;124m'\u001B[39m, to_timestamp(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_timestamp\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mcast(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m)) \\\n\u001B[1;32m      7\u001B[0m   \u001B[38;5;241m.\u001B[39mshow(truncate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\n\u001B[0;31mNameError\u001B[0m: name 'col' is not defined","errorSummary":"<span class='ansi-red-fg'>NameError</span>: name 'col' is not defined","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n","\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n","File \u001B[0;32m<command-3138232597037740>:2\u001B[0m\n","\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Using Cast to convert Timestamp String to DateType\u001B[39;00m\n","\u001B[0;32m----> 2\u001B[0m df\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate_type\u001B[39m\u001B[38;5;124m'\u001B[39m, col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_timestamp\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mcast(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m)) \\\n","\u001B[1;32m      3\u001B[0m        \u001B[38;5;241m.\u001B[39mshow(truncate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n","\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Using Cast to convert TimestampType to DateType\u001B[39;00m\n","\u001B[1;32m      6\u001B[0m df\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate_type\u001B[39m\u001B[38;5;124m'\u001B[39m, to_timestamp(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_timestamp\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mcast(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m)) \\\n","\u001B[1;32m      7\u001B[0m   \u001B[38;5;241m.\u001B[39mshow(truncate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n","\n","\u001B[0;31mNameError\u001B[0m: name 'col' is not defined"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import *\n\n# Using Cast to convert Timestamp String to DateType\ndf.withColumn('date_type', col('input_timestamp').cast('date')) \\\n       .show(truncate=False)\n\n# Using Cast to convert TimestampType to DateType\ndf.withColumn('date_type', to_timestamp('input_timestamp').cast('date')) \\\n  .show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"cc16132f-9c39-4649-9927-33a477ee2f37","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2019-06-24 12:01:19.000|2019-06-24|\n+---+-----------------------+----------+\n\n+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2019-06-24 12:01:19.000|2019-06-24|\n+---+-----------------------+----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.select(to_date(lit('06-24-2019 12:01:19.000'),'MM-dd-yyyy HH:mm:ss.SSSS')) \\\n  .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d0c064e7-7b4f-428a-b074-7b527ee5ff9f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------------------------------------------------------+\n|to_date(06-24-2019 12:01:19.000, MM-dd-yyyy HH:mm:ss.SSSS)|\n+----------------------------------------------------------+\n|                                                2019-06-24|\n+----------------------------------------------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#SQL TimestampType to DateType\nspark.sql(\"select to_date(current_timestamp) as date_type\")\n#SQL CAST TimestampType to DateType\nspark.sql(\"select date(to_timestamp('2019-06-24 12:01:19.000')) as date_type\")\n#SQL CAST timestamp string to DateType\nspark.sql(\"select date('2019-06-24 12:01:19.000') as date_type\")\n#SQL Timestamp String (default format) to DateType\nspark.sql(\"select to_date('2019-06-24 12:01:19.000') as date_type\")\n#SQL Custom Timeformat to DateType\nspark.sql(\"select to_date('06-24-2019 12:01:19.000','MM-dd-yyyy HH:mm:ss.SSSS') as date_type\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e7b6c939-2457-48a2-b19b-905719a08e60","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[6]: DataFrame[date_type: date]"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\n# Create SparkSession\nspark = SparkSession.builder \\\n          .appName('SparkByExamples.com') \\\n          .getOrCreate()\n\ndf=spark.createDataFrame(\n        data = [ (\"1\",\"2019-06-24 12:01:19.000\")],\n        schema=[\"id\",\"input_timestamp\"])\ndf.printSchema()\n\n\nfrom pyspark.sql.functions import *\n\n# Using Cast to convert Timestamp String to DateType\ndf.withColumn('date_type', col('input_timestamp').cast('date')) \\\n       .show(truncate=False)\n\n# Using Cast to convert TimestampType to DateType\ndf.withColumn('date_type', to_timestamp('input_timestamp').cast('date')) \\\n  .show(truncate=False)\n\ndf.select(to_date(lit('06-24-2019 12:01:19.000'),'MM-dd-yyyy HH:mm:ss.SSSS')) \\\n  .show()\n  \n#Timestamp String to DateType\ndf.withColumn(\"date_type\",to_date(\"input_timestamp\")) \\\n  .show(truncate=False)\n\n#Timestamp Type to DateType\ndf.withColumn(\"date_type\",to_date(current_timestamp())) \\\n  .show(truncate=False) \n\ndf.withColumn(\"ts\",to_timestamp(col(\"input_timestamp\"))) \\\n  .withColumn(\"datetype\",to_date(col(\"ts\"))) \\\n  .show(truncate=False)\n    \n#SQL TimestampType to DateType\nspark.sql(\"select to_date(current_timestamp) as date_type\")\n#SQL CAST TimestampType to DateType\nspark.sql(\"select date(to_timestamp('2019-06-24 12:01:19.000')) as date_type\")\n#SQL CAST timestamp string to DateType\nspark.sql(\"select date('2019-06-24 12:01:19.000') as date_type\")\n#SQL Timestamp String (default format) to DateType\nspark.sql(\"select to_date('2019-06-24 12:01:19.000') as date_type\")\n#SQL Custom Timeformat to DateType\nspark.sql(\"select to_date('06-24-2019 12:01:19.000','MM-dd-yyyy HH:mm:ss.SSSS') as date_type\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"85cd1fea-0846-4d1e-ba9a-f1908898016f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-timestamp-date","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
